import os
import time
import textwrap
import streamlit as st
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from notion_client import Client
import openai

from dotenv import load_dotenv
load_dotenv()

# ç’°å¢ƒå¤‰æ•°ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
required_env_vars = [
    "AZURE_SEARCH_ENDPOINT",
    "AZURE_SEARCH_API_KEY",
    "AZURE_OPENAI_ENDPOINT",
    "AZURE_OPENAI_API_KEY",
    "NOTION_API_KEY",
    "NOTION_DATABASE_ID"
]

missing_vars = [var for var in required_env_vars if not os.getenv(var)]
if missing_vars:
    raise ValueError(f"Missing required environment variables: {', '.join(missing_vars)}")

# Azure AI Searchè¨­å®š
index_name = "index1"
endpoint = os.environ["AZURE_SEARCH_ENDPOINT"]
key = os.environ["AZURE_SEARCH_API_KEY"]
search_client = SearchClient(endpoint, index_name, AzureKeyCredential(key))

# Azure OpenAIè¨­å®š
openai.api_type = 'azure'
openai.api_base = os.environ["AZURE_OPENAI_ENDPOINT"]
openai.api_key = os.environ["AZURE_OPENAI_API_KEY"]
emb_model_name = "text-embedding-3-large"
llm_model_name = "gpt-4o"
openai.api_version = "2024-02-01"

# Notionè¨­å®š
notion = Client(auth=os.environ["NOTION_API_KEY"])
DB_ID = os.environ["NOTION_DATABASE_ID"]

def get_embedding(text, retries=3):
    """ãƒ†ã‚­ã‚¹ãƒˆã®embeddingã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    for attempt in range(retries):
        try:
            response = openai.Embedding.create(input=text, engine=emb_model_name)
            return response["data"][0]["embedding"]
        except Exception as e:
            if attempt == retries - 1:
                raise e
            time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–

def initialize_search_index():
    """Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’Azure AI Searchã«ç™»éŒ²ã™ã‚‹é–¢æ•°"""
    docs = []
    progress_text = "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ä¸­..."
    try:
        # Notionã‹ã‚‰ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        pages = notion.databases.query(database_id=DB_ID)["results"]
        total_pages = len(pages)
        
        progress_bar = st.progress(0, text=progress_text)
        for i, page in enumerate(pages, 1):
            progress_bar.progress(i / total_pages, f"{progress_text} ({i}/{total_pages}ãƒšãƒ¼ã‚¸å‡¦ç†ä¸­)")
            
            # ãƒšãƒ¼ã‚¸IDã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
            page_id = page["id"]
            title_raw = page["properties"]["åå‰"]["title"]
            title = title_raw[0]["plain_text"] if title_raw else "Untitled"

            # å­ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡º
            blocks = notion.blocks.children.list(block_id=page_id)["results"]
            body_lines = []
            for b in blocks:
                block_type = b["type"]
                if "rich_text" in b[block_type]:
                    rich_text = b[block_type]["rich_text"]
                    line = "".join([t["plain_text"] for t in rich_text])
                    body_lines.append(line)

            full_text = textwrap.dedent("\n".join(body_lines))

            # Embeddingã®ç”Ÿæˆ
            try:
                embedding = get_embedding(full_text)
                time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            except Exception as e:
                st.warning(f"Embeddingç”Ÿæˆã‚¨ãƒ©ãƒ¼ (ID: {page_id}): {str(e)}")
                continue

            doc = {
                "id": page_id,
                "category": title,
                "text": full_text,
                "text_vector": embedding,
            }
            docs.append(doc)

            # Azure AI Searchã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        if docs:
            result = search_client.upload_documents(documents=docs)
            success_count = sum(1 for r in result if r.succeeded)
            st.success(f"âœ… {success_count}/{len(docs)} ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
            progress_bar.empty()
            return True
        else:
            st.warning("âš ï¸ ç™»éŒ²å¯¾è±¡ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            progress_bar.empty()
            return False

    except Exception as e:
        st.error(f"åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        progress_bar.empty()
        return False

def cognitive_search(query, k=3):
    """Azure AI Searchã§é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢ã™ã‚‹é–¢æ•°"""
    try:
        embedding = get_embedding(query)
        results = search_client.search(
            search_text="",
            vectors=[{
                "value": embedding,
                "k": k,
                "fields": "text_vector"
            }]
        )
        documents = []
        for result in results:
            documents.append(result["text"])
        return documents
    except Exception as e:
        st.error(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return []

def generate_response(question, context_docs):
    """LLMã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    try:
        context = "\n\n".join(context_docs)
        prompt = f"""
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
{context}
"""
        completion = openai.ChatCompletion.create(
            engine=llm_model_name,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": question},
            ],
            temperature=0.2,
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å›ç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"

# Streamlit UIã®æ§‹ç¯‰
st.title("ğŸ“š Azure RAG Chatbot")

# åˆæœŸåŒ–å‡¦ç†
if "messages" not in st.session_state:
    st.session_state.messages = []

if "initialized" not in st.session_state:
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ä¸­..."):
        success = initialize_search_index()
        st.session_state.initialized = success

if not st.session_state.initialized:
    st.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# æ›´æ–°ãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ”„ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°"):
    with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ä¸­..."):
        success = initialize_search_index()
        if success:
            st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            st.error("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å–å¾—
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # æ¤œç´¢çµæœã‚’å–å¾—
    with st.spinner("æ¤œç´¢ä¸­..."):
        docs = cognitive_search(prompt)

    if docs:
        # LLMã‹ã‚‰ã®å›ç­”ã‚’ç”Ÿæˆ
        with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
            answer = generate_response(prompt, docs)

        # å›ç­”ã‚’è¡¨ç¤º
        with st.chat_message("assistant"):
            st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})
    else:
        with st.chat_message("assistant"):
            st.markdown("ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
